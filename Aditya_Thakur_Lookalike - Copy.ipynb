{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a380bf3-fbe7-44c6-a240-0d5afe690ee4",
   "metadata": {},
   "source": [
    "**Step 1: Import Libraries and Load Data**\n",
    "\n",
    "\n",
    "We load the datasets and check their structure to understand the features we will use for the lookalike model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d59febc-5c30-4563-82c7-4c0700f6b877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID        CustomerName         Region  SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
      "2      C0003      Michael Rivera  South America  2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
      "4      C0005         Laura Weber           Asia  2022-08-15\n",
      "  ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n",
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Paths to datasets\n",
    "customers_path = \"Customers.csv\"\n",
    "products_path = \"Products.csv\"\n",
    "transactions_path = \"Transactions.csv\"\n",
    "\n",
    "# Load datasets\n",
    "customers = pd.read_csv(customers_path)\n",
    "products = pd.read_csv(products_path)\n",
    "transactions = pd.read_csv(transactions_path)\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(customers.head())\n",
    "print(products.head())\n",
    "print(transactions.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b34ceb-c835-4d5f-8f73-e29b21cd9024",
   "metadata": {},
   "source": [
    "**Step 2: Preprocess and Merge Data**\n",
    "\n",
    "We merge the datasets to combine customer profiles with transaction history and aggregate features like total spending, quantity purchased, and product preferences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0810ba6f-8c27-44c0-a979-317fd70a1484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID         Region  TotalValue  Quantity  \\\n",
      "0      C0001  South America     3354.52        12   \n",
      "1      C0002           Asia     1862.74        10   \n",
      "2      C0003  South America     2725.38        14   \n",
      "3      C0004  South America     5354.88        23   \n",
      "4      C0005           Asia     2034.24         7   \n",
      "\n",
      "                                         ProductName  \n",
      "0  HomeSense Wall Art TechPro Headphones ActiveWe...  \n",
      "1  BookWorld Cookware Set BookWorld Rug ComfortLi...  \n",
      "2  ActiveWear T-Shirt ActiveWear Rug ActiveWear C...  \n",
      "3  BookWorld Bluetooth Speaker TechPro Rug TechPr...  \n",
      "4  TechPro Smartwatch ActiveWear Cookware Set Com...  \n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime\n",
    "customers['SignupDate'] = pd.to_datetime(customers['SignupDate'])\n",
    "transactions['TransactionDate'] = pd.to_datetime(transactions['TransactionDate'])\n",
    "\n",
    "# Merge datasets\n",
    "customer_transactions = transactions.merge(customers, on='CustomerID').merge(products, on='ProductID')\n",
    "\n",
    "# Aggregate transaction history for each customer\n",
    "customer_profiles = customer_transactions.groupby('CustomerID').agg({\n",
    "    'Region': 'first',  # Region is a categorical feature\n",
    "    'TotalValue': 'sum',  # Total spending\n",
    "    'Quantity': 'sum',  # Total items purchased\n",
    "    'ProductName': lambda x: ' '.join(x)  # Combine purchased products into a single string\n",
    "}).reset_index()\n",
    "\n",
    "# Display the aggregated customer profiles\n",
    "print(customer_profiles.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872b6ed6-c498-4b44-873b-b0407ea43ea2",
   "metadata": {},
   "source": [
    "**Step 3: Encode Categorical and Textual Features**\n",
    "\n",
    "We encode the categorical Region column and use TF-IDF to convert the textual ProductName feature into numerical vectors. This creates a comprehensive feature set for similarity computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2128a7f-0012-48f1-b91a-5e2718c2e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID  TotalValue  Quantity  Region_Asia  Region_Europe  \\\n",
      "0      C0001     3354.52        12        False          False   \n",
      "1      C0002     1862.74        10         True          False   \n",
      "2      C0003     2725.38        14        False          False   \n",
      "3      C0004     5354.88        23        False          False   \n",
      "4      C0005     2034.24         7         True          False   \n",
      "\n",
      "   Region_North America  Region_South America  activewear       art  \\\n",
      "0                 False                  True    0.181413  0.370663   \n",
      "1                 False                 False    0.000000  0.000000   \n",
      "2                 False                  True    0.727207  0.000000   \n",
      "3                 False                  True    0.253108  0.000000   \n",
      "4                 False                 False    0.255203  0.000000   \n",
      "\n",
      "   biography  ...  shoes  smartphone  smartwatch  soundwave   speaker  \\\n",
      "0        0.0  ...    0.0         0.0    0.267673   0.382563  0.000000   \n",
      "1        0.0  ...    0.0         0.0    0.000000   0.000000  0.000000   \n",
      "2        0.0  ...    0.0         0.0    0.268246   0.000000  0.000000   \n",
      "3        0.0  ...    0.0         0.0    0.186729   0.133438  0.261307   \n",
      "4        0.0  ...    0.0         0.0    0.376549   0.000000  0.000000   \n",
      "\n",
      "    sweater   techpro  textbook      vase      wall  \n",
      "0  0.000000  0.214696  0.000000  0.000000  0.370663  \n",
      "1  0.378316  0.234731  0.000000  0.000000  0.000000  \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3  0.000000  0.449315  0.217696  0.302343  0.000000  \n",
      "4  0.000000  0.302023  0.000000  0.000000  0.000000  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# One-hot encode 'Region'\n",
    "customer_profiles = pd.get_dummies(customer_profiles, columns=['Region'], prefix='Region')\n",
    "\n",
    "# Apply TF-IDF vectorization on product preferences\n",
    "tfidf = TfidfVectorizer()\n",
    "product_vectors = tfidf.fit_transform(customer_profiles['ProductName'])\n",
    "\n",
    "# Add the TF-IDF product features to the profile\n",
    "product_features = pd.DataFrame(product_vectors.toarray(), columns=tfidf.get_feature_names_out())\n",
    "customer_profiles = pd.concat([customer_profiles, product_features], axis=1)\n",
    "\n",
    "# Drop the original 'ProductName' column\n",
    "customer_profiles = customer_profiles.drop(columns=['ProductName'])\n",
    "\n",
    "# Display processed customer profiles\n",
    "print(customer_profiles.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf3144d-a5f6-43e4-ab18-628474be22a5",
   "metadata": {},
   "source": [
    "**Step 4: Standardize Numerical Features**\n",
    "\n",
    "We standardize numerical features like TotalValue and Quantity to ensure they are on the same scale, which is crucial for similarity computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44814bfb-b080-4a2d-bb46-9c63d985ff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TotalValue  Quantity\n",
      "0   -0.061701 -0.122033\n",
      "1   -0.877744 -0.448000\n",
      "2   -0.405857  0.203934\n",
      "3    1.032547  1.670787\n",
      "4   -0.783929 -0.936951\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary library for StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify numerical features for standardization\n",
    "numerical_features = ['TotalValue', 'Quantity']\n",
    "scaler = StandardScaler()\n",
    "customer_profiles[numerical_features] = scaler.fit_transform(customer_profiles[numerical_features])\n",
    "\n",
    "# Display standardized features\n",
    "print(customer_profiles[numerical_features].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ee097-002d-4693-a4c8-c817610288ed",
   "metadata": {},
   "source": [
    "**Step 5: Compute Similarity Scores**\n",
    "\n",
    "We compute the cosine similarity between all customer profiles, generating a similarity matrix where each entry represents the similarity score between two customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d15f7a86-7a9c-4148-b53c-b073c95f2715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID     C0001     C0002     C0003     C0004     C0005\n",
      "CustomerID                                                  \n",
      "C0001       1.000000  0.065015  0.570447  0.315788  0.221276\n",
      "C0002       0.065015  1.000000  0.273564 -0.276564  0.809574\n",
      "C0003       0.570447  0.273564  1.000000  0.380172  0.262157\n",
      "C0004       0.315788 -0.276564  0.380172  1.000000 -0.416910\n",
      "C0005       0.221276  0.809574  0.262157 -0.416910  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity between all customer profiles\n",
    "feature_matrix = customer_profiles.drop(columns=['CustomerID']).values\n",
    "similarity_matrix = cosine_similarity(feature_matrix)\n",
    "\n",
    "# Create a DataFrame for similarity scores, using customer IDs only as the index and columns\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=customer_profiles['CustomerID'], columns=customer_profiles['CustomerID'])\n",
    "\n",
    "# Display similarity scores for the first 5 customers\n",
    "print(similarity_df.iloc[:5, :5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd04cf-0f2a-4ddc-9116-cb8d904bad94",
   "metadata": {},
   "source": [
    "**Step 6: Recommend Lookalike Customers**\n",
    "\n",
    "This step identifies the top 3 similar customers for each of the first 20 customers and stores them with their similarity scores in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48548a9a-239e-4521-93b8-e5c971d4a07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C0001': [('C0129', 0.7576118846924658), ('C0191', 0.7334505744495917), ('C0190', 0.7145328106140103)], 'C0002': [('C0005', 0.8095743769357011), ('C0088', 0.7999247759859655), ('C0128', 0.7980000045533396)], 'C0003': [('C0181', 0.8051897119210434), ('C0133', 0.7602259179936883), ('C0076', 0.740114050600447)], 'C0004': [('C0087', 0.9015628272797028), ('C0165', 0.8975234616360919), ('C0102', 0.8848866680650116)], 'C0005': [('C0128', 0.9106119416124159), ('C0159', 0.8757594672235632), ('C0007', 0.8199665579164385)], 'C0006': [('C0187', 0.8816113941169941), ('C0171', 0.7627345113449657), ('C0191', 0.7396688197951593)], 'C0007': [('C0005', 0.8199665579164385), ('C0159', 0.812400698309829), ('C0146', 0.7668000095942176)], 'C0008': [('C0109', 0.84322921272305), ('C0068', 0.8317614369573453), ('C0122', 0.8015308221101916)], 'C0009': [('C0062', 0.8960695793373862), ('C0060', 0.8856282360396891), ('C0198', 0.85977143392587)], 'C0010': [('C0166', 0.7634679962440855), ('C0121', 0.7360153780537382), ('C0073', 0.7309824884539794)], 'C0011': [('C0107', 0.7419016028736336), ('C0118', 0.7018581986746679), ('C0137', 0.6932984361340585)], 'C0012': [('C0148', 0.9166583456331154), ('C0163', 0.9022865403477555), ('C0104', 0.8609182402236334)], 'C0013': [('C0102', 0.9314366991768117), ('C0096', 0.9024098136985914), ('C0099', 0.8878357307124557)], 'C0014': [('C0060', 0.8783649092458441), ('C0198', 0.8771405491667854), ('C0009', 0.8585181767425644)], 'C0015': [('C0033', 0.8766994642649291), ('C0058', 0.8466705997536059), ('C0020', 0.8330195547823281)], 'C0016': [('C0125', 0.7276069955920074), ('C0183', 0.7017005437915633), ('C0185', 0.6928338666817557)], 'C0017': [('C0041', 0.8907966539898929), ('C0075', 0.8661739063766967), ('C0124', 0.8172800997440489)], 'C0018': [('C0068', 0.8776806512740419), ('C0046', 0.8599164082034545), ('C0059', 0.8315233714939757)], 'C0019': [('C0070', 0.8421844927743625), ('C0199', 0.7860366178944749), ('C0121', 0.7803539228283342)], 'C0020': [('C0058', 0.8615344712188334), ('C0033', 0.8583557370200212), ('C0015', 0.8330195547823281)]}\n"
     ]
    }
   ],
   "source": [
    "# Function to get top 3 lookalike customers\n",
    "def get_top_lookalikes(customer_id, similarity_df, top_n=3):\n",
    "    similar_customers = similarity_df[customer_id].sort_values(ascending=False).iloc[1:top_n+1]\n",
    "    return similar_customers.index.tolist(), similar_customers.values.tolist()\n",
    "\n",
    "# Create the Lookalike map for CustomerID: C0001 - C0020\n",
    "lookalike_map = {}\n",
    "for customer_id in customer_profiles['CustomerID'].iloc[:20]:\n",
    "    similar_ids, scores = get_top_lookalikes(customer_id, similarity_df)\n",
    "    lookalike_map[customer_id] = list(zip(similar_ids, scores))\n",
    "\n",
    "# Display the Lookalike map\n",
    "print(lookalike_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ccc0a-4e04-4dfa-9f26-5173238eecfc",
   "metadata": {},
   "source": [
    "**Step 7: Save Lookalike Map to CSV**\n",
    "\n",
    "The lookalike_map is converted into a DataFrame and saved as Aditya_Thakur_Lookalike.csv, meeting the task requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8ef799-7e72-4cf7-b7ef-bd6919cbde2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookalike map saved to Lookalike.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert lookalike_map to a DataFrame and save as CSV\n",
    "lookalike_list = []\n",
    "for cust_id, similar_list in lookalike_map.items():\n",
    "    for similar_cust, score in similar_list:\n",
    "        lookalike_list.append({'cust_id': cust_id, 'similar_cust_id': similar_cust, 'score': score})\n",
    "\n",
    "lookalike_df = pd.DataFrame(lookalike_list)\n",
    "lookalike_df.to_csv('Aditya_Thakur_Lookalike.csv', index=False)\n",
    "\n",
    "print(\"Lookalike map saved to Lookalike.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b0bf54-6a68-4654-af24-77a5675f69cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
